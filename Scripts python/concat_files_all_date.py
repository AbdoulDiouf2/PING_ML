import pandas as pd
import os
from datetime import datetime
import logging

def setup_logging(log_file="Logs/execution_logs.log"):
    """
    Configure le systÃ¨me de logging.
    
    Args:
        log_file (str): Nom du fichier de log
    """
    log_format = "%(asctime)s | %(levelname)s | %(message)s"
    date_format = "%Y-%m-%d %H:%M:%S"
    
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        datefmt=date_format,
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8', mode='a'),
            logging.StreamHandler()
        ]
    )
    
    logging.info("="*50)
    logging.info("ğŸš€ DÃ©but d'une nouvelle session de traitement multi-annÃ©es")

def concatener_fichiers_mensuels(dossier_path, annee):
    """
    ConcatÃ¨ne tous les fichiers mensuels d'une annÃ©e en un seul fichier CSV.
    """
    all_dfs = []
    fichiers_traites = 0
    fichiers_erreur = 0
    
    logging.info(f"ğŸ“… Traitement de l'annÃ©e {annee}")
    logging.info(f"ğŸ“‚ Dossier: {dossier_path}")
    
    for i in range(1, 13):
        nom_fichier = f"{i}-{'janvier' if i==1 else 'fevrier' if i==2 else 'mars' if i==3 else 'avril' if i==4 else 'mai' if i==5 else 'juin' if i==6 else 'juillet' if i==7 else 'aout' if i==8 else 'septembre' if i==9 else 'octobre' if i==10 else 'novembre' if i==11 else 'decembre'}{annee}.xlsx"
        chemin_complet = os.path.join(dossier_path, nom_fichier)
        
        try:
            logging.info(f"ğŸ“– Lecture du fichier {nom_fichier}...")
            df = pd.read_excel(chemin_complet)
            
            colonnes_attendues = ['ETBDES', 'ARTDES', 'DATE', 'QUANTITE']
            if not all(col in df.columns for col in colonnes_attendues):
                logging.warning(f"âš ï¸ Colonnes manquantes dans {nom_fichier}")
                fichiers_erreur += 1
                continue
                
            all_dfs.append(df)
            fichiers_traites += 1
            logging.info(f"âœ… Fichier {nom_fichier} traitÃ© avec succÃ¨s ({len(df)} lignes)")
            
        except Exception as e:
            logging.error(f"âŒ Erreur lors de la lecture de {nom_fichier}: {str(e)}")
            fichiers_erreur += 1
    
    if not all_dfs:
        error_msg = f"âŒ Aucun fichier n'a pu Ãªtre traitÃ© correctement pour l'annÃ©e {annee}"
        logging.error(error_msg)
        return None
    
    logging.info(f"ğŸ”„ ConcatÃ©nation des fichiers de {annee}...")
    df_final = pd.concat(all_dfs, ignore_index=True)
    df_final = df_final.sort_values(['DATE', 'ETBDES', 'ARTDES'])
    
    nom_fichier_sortie = f"donnees_completes_{annee}.csv"
    df_final.to_csv(nom_fichier_sortie, index=False)
    
    logging.info(f"âœ¨ RÃ©sumÃ© pour {annee} âœ¨")
    logging.info(f"ğŸ“Š Fichiers traitÃ©s avec succÃ¨s: {fichiers_traites}")
    logging.info(f"âš ï¸ Fichiers en erreur: {fichiers_erreur}")
    logging.info(f"ğŸ“ Nombre total de lignes: {len(df_final)}")
    logging.info(f"ğŸ’¾ Fichier sauvegardÃ©: {nom_fichier_sortie}")
    
    return df_final

def traiter_toutes_annees(dossier_base="Logistique-new", annees=[2022, 2023, 2024]):
    """
    Traite les donnÃ©es pour plusieurs annÃ©es et crÃ©e un fichier consolidÃ©.
    
    Args:
        dossier_base (str): Chemin du dossier base
        annees (list): Liste des annÃ©es Ã  traiter
    """
    setup_logging()
    all_years_dfs = []
    stats_globales = {
        "annees_traitees": 0,
        "annees_erreur": 0,
        "total_lignes": 0
    }
    
    logging.info(f"ğŸ¯ DÃ©but du traitement multi-annÃ©es: {annees}")
    
    for annee in annees:
        dossier = os.path.join(dossier_base, str(annee))
        try:
            df_annee = concatener_fichiers_mensuels(dossier, str(annee))
            if df_annee is not None:
                all_years_dfs.append(df_annee)
                stats_globales["annees_traitees"] += 1
                stats_globales["total_lignes"] += len(df_annee)
            else:
                stats_globales["annees_erreur"] += 1
        except Exception as e:
            logging.error(f"ğŸ’¥ Erreur critique pour l'annÃ©e {annee}: {str(e)}")
            stats_globales["annees_erreur"] += 1
    
    if all_years_dfs:
        # CrÃ©ation du fichier consolidÃ© toutes annÃ©es
        df_final_global = pd.concat(all_years_dfs, ignore_index=True)
        df_final_global = df_final_global.sort_values(['DATE', 'ETBDES', 'ARTDES'])
        
        nom_fichier_global = f"donnees_completes_{min(annees)}-{max(annees)}.csv"
        df_final_global.to_csv(nom_fichier_global, index=False)
        
        # RÃ©sumÃ© global
        logging.info("ğŸŒŸ"*30 + " RÃ‰SUMÃ‰ GLOBAL " + "ğŸŒŸ"*30)
        logging.info(f"ğŸ“Š AnnÃ©es traitÃ©es avec succÃ¨s: {stats_globales['annees_traitees']}")
        logging.info(f"âš ï¸ AnnÃ©es en erreur: {stats_globales['annees_erreur']}")
        logging.info(f"ğŸ“ Nombre total de lignes (toutes annÃ©es): {stats_globales['total_lignes']}")
        logging.info(f"ğŸ’¾ Fichier consolidÃ©: {nom_fichier_global}")
        logging.info("ğŸŒŸ"*75)
    else:
        logging.error("ğŸ’¥ Aucune annÃ©e n'a pu Ãªtre traitÃ©e correctement")

# Exemple d'utilisation
if __name__ == "__main__":
    try:
        traiter_toutes_annees("Logistique-new", [2022, 2023, 2024])
    except Exception as e:
        logging.error(f"ğŸ’¥ Erreur critique globale: {str(e)}")